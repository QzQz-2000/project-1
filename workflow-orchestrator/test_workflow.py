import json
import asyncio
import aiohttp
import pandas as pd
import os
from datetime import datetime

async def test_workflow():
    """æµ‹è¯•å·¥ä½œæµï¼Œå¹¶æ‰“å°æœ€ç»ˆç»“æœ"""
    print("ğŸ§ª Testing Simple Workflow Engine")
    print("=" * 50)
    
    # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
    os.makedirs('data', exist_ok=True)
    
    # ç”Ÿæˆæµ‹è¯•CSV
    test_data = pd.DataFrame({
        'timestamp': pd.date_range('2024-01-01', periods=50, freq='H'),
        'value': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55] * 5,
        'category': ['A', 'B'] * 25
    })
    test_data.to_csv('data/test_data.csv', index=False)
    print(f"âœ… Created test data: {len(test_data)} rows")
    
    # 2. ç­‰å¾…æœåŠ¡å¯åŠ¨ (é‡è¦!)
    print("â³ Waiting for services to start...")
    await asyncio.sleep(20)
    
    # 3. å®šä¹‰æµ‹è¯•å·¥ä½œæµ
    workflow = {
        "name": "Moving Average and Threshold Alarm Workflow",
        "description": "Load data -> Calculate moving average -> Apply threshold alarm",
        "steps": [
            {
                "name": "load_data",
                "task_type": "DATA",
                "data_source_config": {
                    "source_type": "csv",
                    "query_config": {
                        "file_path": "/app/data/test_data.csv"
                    }
                }
            },
            {
                "name": "calculate_ma",
                "task_type": "FUNCTION",
                "function_name": "MovingAverage",
                "config": {
                    "field": "value",
                    "window": 5
                },
                "dependencies": ["load_data"]
            },
            {
                "name": "threshold_alarm",
                "task_type": "FUNCTION",
                "function_name": "ThresholdAlarm",
                "config": {
                    "field": "value_ma5",
                    "threshold": 30,
                    "mode": "greater"
                },
                "dependencies": ["calculate_ma"]
            }
        ]
    }
    
    async with aiohttp.ClientSession() as session:
        try:
            # 4. æäº¤å·¥ä½œæµ
            print("\nğŸš€ Submitting workflow...")
            submit_url = 'http://localhost:8001/workflows/submit'
            payload = {
                "workflow": workflow,
                "submitted_by": "test_script"
            }
            async with session.post(submit_url, json=payload) as response:
                if response.status == 200:
                    result = await response.json()
                    workflow_id = result.get('workflow_id')
                    print(f"âœ… Workflow submitted with ID: {workflow_id}")
                else:
                    print(f"âŒ Failed to submit workflow: {response.status}")
                    print(await response.text())
                    return
            
            # 5. æŒç»­æŸ¥è¯¢å·¥ä½œæµçŠ¶æ€ï¼Œç›´åˆ°å®Œæˆ
            print("â³ Polling workflow status until completion...")
            status_url = f'http://localhost:8001/workflows/{workflow_id}/status'
            
            max_retries = 30
            for i in range(max_retries):
                await asyncio.sleep(2)
                async with session.get(status_url) as response:
                    if response.status == 200:
                        status_info = await response.json()
                        workflow_status = status_info['status']
                        print(f"  - Status check {i+1}: {workflow_status.upper()}")
                        if workflow_status in ['completed', 'failed']:
                            print(f"âœ… Workflow completed with status: {workflow_status.upper()}")
                            break
                    else:
                        print(f"âŒ Failed to get workflow status: {response.status}")
                        print(await response.text())
                        return
            else:
                print("âš ï¸ Workflow timed out or did not complete within the expected time.")
                return
            
            # 6. è·å–æœ€ç»ˆç»“æœ
            print("\nğŸ“Š Fetching final result from API...")
            result_url = f'http://localhost:8001/workflows/{workflow_id}/tasks/threshold_alarm/result'
            
            async with session.get(result_url) as response:
                if response.status == 200:
                    result_data = await response.json()
                    print("âœ… Successfully fetched final result!")
                    
                    if result_data:
                        result_df = pd.DataFrame(result_data)
                        print("\n--- Final Results (threshold_alarm) ---")
                        print(result_df)
                    else:
                        print("No data returned for final task.")
                else:
                    print(f"âŒ Failed to get final result: {response.status}")
                    print(await response.text())
            
            print("\nğŸ‰ Test completed!")
            
        except aiohttp.ClientConnectorError as e:
            print(f"âŒ Connection Error: The API server might not be running or reachable at http://localhost:8000. Error: {e}")
        except Exception as e:
            print(f"âŒ An unexpected error occurred: {e}")

if __name__ == "__main__":
    asyncio.run(test_workflow())

# import json
# import asyncio
# import aiohttp
# import pandas as pd
# import os
# from datetime import datetime

# async def test_workflow():
#     """æµ‹è¯•å·¥ä½œæµï¼Œä½¿ç”¨æ­£ç¡®çš„ç¯å¢ƒéš”ç¦»APIç«¯ç‚¹"""
#     print("æµ‹è¯•ç®€å•å·¥ä½œæµå¼•æ“")
#     print("=" * 50)
    
#     # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
#     os.makedirs('data', exist_ok=True)
    
#     # ç”Ÿæˆæµ‹è¯•CSV
#     test_data = pd.DataFrame({
#         'timestamp': pd.date_range('2024-01-01', periods=50, freq='H'),
#         'value': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55] * 5,
#         'category': ['A', 'B'] * 25
#     })
#     test_data.to_csv('data/test_data.csv', index=False)
#     print(f"åˆ›å»ºæµ‹è¯•æ•°æ®: {len(test_data)} è¡Œ")
    
#     # 2. ç­‰å¾…æœåŠ¡å¯åŠ¨
#     print("ç­‰å¾…æœåŠ¡å¯åŠ¨...")
#     await asyncio.sleep(20)
    
#     # 3. å®šä¹‰æµ‹è¯•ç¯å¢ƒID
#     environment_id = "test_env_001"
    
#     # 4. å®šä¹‰æµ‹è¯•å·¥ä½œæµ
#     workflow = {
#         "name": "ç§»åŠ¨å¹³å‡å’Œé˜ˆå€¼å‘Šè­¦å·¥ä½œæµ",
#         "description": "åŠ è½½æ•°æ® -> è®¡ç®—ç§»åŠ¨å¹³å‡ -> åº”ç”¨é˜ˆå€¼å‘Šè­¦",
#         "steps": [
#             {
#                 "name": "load_data",
#                 "task_type": "DATA",
#                 "data_source_config": {
#                     "source_type": "influxdb",
#                     "query_config": {
#                         "measurement": "test_measurement",
#                         "fields": ["value"],
#                         "start": "-4h",             
#                         "stop": "now()",
#                         "pivot": True   
#                     }
#                 }
#             },
#             {
#                 "name": "calculate_ma",
#                 "task_type": "FUNCTION",
#                 "function_name": "MovingAverage",
#                 "config": {
#                     "field": "value",
#                     "window": 5
#                 },
#                 "dependencies": ["load_data"]
#             },
#             {
#                 "name": "threshold_alarm",
#                 "task_type": "FUNCTION",
#                 "function_name": "ThresholdAlarm",
#                 "config": {
#                     "field": "value_ma5",
#                     "threshold": 30,
#                     "mode": "greater"
#                 },
#                 "dependencies": ["calculate_ma"]
#             }
#         ]
#     }
    
#     async with aiohttp.ClientSession() as session:
#         try:
#             # 5. æäº¤å·¥ä½œæµåˆ°æŒ‡å®šç¯å¢ƒ
#             print(f"\nå‘ç¯å¢ƒ {environment_id} æäº¤å·¥ä½œæµ...")
#             submit_url = f'http://localhost:8001/environments/{environment_id}/workflows/submit'
#             payload = {
#                 "workflow": workflow,
#                 "submitted_by": "test_script"
#             }
#             async with session.post(submit_url, json=payload) as response:
#                 if response.status == 200:
#                     result = await response.json()
#                     workflow_id = result.get('workflow_id')
#                     print(f"å·¥ä½œæµå·²æäº¤ï¼ŒID: {workflow_id}")
#                     print(f"   ç¯å¢ƒID: {result.get('environment_id')}")
#                 else:
#                     print(f"å·¥ä½œæµæäº¤å¤±è´¥: {response.status}")
#                     print(await response.text())
#                     return
            
#             # 6. æŒç»­æŸ¥è¯¢å·¥ä½œæµçŠ¶æ€ï¼Œç›´åˆ°å®Œæˆ
#             print("è½®è¯¢å·¥ä½œæµçŠ¶æ€ç›´åˆ°å®Œæˆ...")
#             status_url = f'http://localhost:8001/environments/{environment_id}/workflows/{workflow_id}/status'
            
#             max_retries = 30
#             for i in range(max_retries):
#                 await asyncio.sleep(2)
#                 async with session.get(status_url) as response:
#                     if response.status == 200:
#                         status_info = await response.json()
#                         workflow_status = status_info['status']
#                         task_stats = status_info.get('task_statistics', {})
#                         print(f"  - çŠ¶æ€æ£€æŸ¥ {i+1}: {workflow_status.upper()}")
#                         print(f"    ä»»åŠ¡ç»Ÿè®¡: {task_stats}")
#                         if workflow_status in ['completed', 'failed']:
#                             print(f"å·¥ä½œæµå®Œæˆï¼ŒçŠ¶æ€: {workflow_status.upper()}")
#                             break
#                     else:
#                         print(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {response.status}")
#                         print(await response.text())
#                         return
#             else:
#                 print("å·¥ä½œæµè¶…æ—¶æˆ–æœªåœ¨é¢„æœŸæ—¶é—´å†…å®Œæˆã€‚")
#                 return
            
#             # 7. è·å–æœ€ç»ˆç»“æœ
#             print("\nä»APIè·å–æœ€ç»ˆç»“æœ...")
#             result_url = f'http://localhost:8001/environments/{environment_id}/workflows/{workflow_id}/tasks/threshold_alarm/result'
            
#             async with session.get(result_url) as response:
#                 if response.status == 200:
#                     result_data = await response.json()
#                     print("æˆåŠŸè·å–æœ€ç»ˆç»“æœ!")
                    
#                     if result_data:
#                         result_df = pd.DataFrame(result_data)
#                         print("\n--- æœ€ç»ˆç»“æœ (threshold_alarm) ---")
#                         print(f"æ•°æ®å½¢çŠ¶: {result_df.shape}")
#                         print("\nå‰10è¡Œ:")
#                         print(result_df.head(10))
                        
#                         # æ˜¾ç¤ºå‘Šè­¦ç»Ÿè®¡
#                         if 'is_alarm' in result_df.columns:
#                             alarm_count = result_df['is_alarm'].sum()
#                             total_count = len(result_df)
#                             print(f"\nå‘Šè­¦ç»Ÿè®¡: {alarm_count}/{total_count} æ¡è®°å½•è§¦å‘å‘Šè­¦")
                        
#                         # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
#                         result_df.to_csv('workflow_result.csv', index=False)
#                         print("ç»“æœå·²ä¿å­˜åˆ° workflow_result.csv")
#                     else:
#                         print("æœ€ç»ˆä»»åŠ¡æœªè¿”å›æ•°æ®ã€‚")
#                 else:
#                     print(f"è·å–æœ€ç»ˆç»“æœå¤±è´¥: {response.status}")
#                     print(await response.text())
            
#             # 8. åˆ—å‡ºç¯å¢ƒä¸­çš„æ‰€æœ‰å·¥ä½œæµ
#             print(f"\nåˆ—å‡ºç¯å¢ƒ {environment_id} ä¸­çš„æ‰€æœ‰å·¥ä½œæµ...")
#             list_url = f'http://localhost:8001/environments/{environment_id}/workflows'
#             async with session.get(list_url) as response:
#                 if response.status == 200:
#                     workflows_data = await response.json()
#                     workflows = workflows_data.get('workflows', [])
#                     print(f"ç¯å¢ƒä¸­å…±æœ‰ {len(workflows)} ä¸ªå·¥ä½œæµ:")
#                     for wf in workflows:
#                         print(f"  - {wf['workflow_id']}: {wf['name']} ({wf['status']})")
#                 else:
#                     print(f"è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {response.status}")
            
#             print("\næµ‹è¯•å®Œæˆ!")
            
#         except aiohttp.ClientConnectorError as e:
#             print(f"è¿æ¥é”™è¯¯: APIæœåŠ¡å™¨å¯èƒ½æœªè¿è¡Œæˆ–æ— æ³•è®¿é—® http://localhost:8001ã€‚é”™è¯¯: {e}")
#         except Exception as e:
#             print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

# async def test_health_check():
#     """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
#     print("\næµ‹è¯•å¥åº·æ£€æŸ¥...")
#     async with aiohttp.ClientSession() as session:
#         try:
#             async with session.get('http://localhost:8001/health') as response:
#                 if response.status == 200:
#                     health_data = await response.json()
#                     print(f"æœåŠ¡å¥åº·çŠ¶æ€: {health_data['status']}")
#                     print(f"   æœåŠ¡çŠ¶æ€: {health_data.get('services', {})}")
#                 else:
#                     print(f"å¥åº·æ£€æŸ¥å¤±è´¥: {response.status}")
#         except Exception as e:
#             print(f"å¥åº·æ£€æŸ¥é”™è¯¯: {e}")

# async def test_functions_list():
#     """æµ‹è¯•å‡½æ•°åˆ—è¡¨ç«¯ç‚¹"""
#     print("\næµ‹è¯•å¯ç”¨å‡½æ•°åˆ—è¡¨...")
#     async with aiohttp.ClientSession() as session:
#         try:
#             async with session.get('http://localhost:8001/functions') as response:
#                 if response.status == 200:
#                     functions_data = await response.json()
#                     functions = functions_data.get('functions', [])
#                     print(f"å¯ç”¨å‡½æ•° ({len(functions)} ä¸ª):")
#                     for func in functions:
#                         print(f"  - {func['name']}: {func['description']} ({func['category']})")
#                 else:
#                     print(f"è·å–å‡½æ•°åˆ—è¡¨å¤±è´¥: {response.status}")
#         except Exception as e:
#             print(f"å‡½æ•°åˆ—è¡¨é”™è¯¯: {e}")

# async def test_environments():
#     """æµ‹è¯•ç¯å¢ƒç®¡ç†ç«¯ç‚¹"""
#     print("\næµ‹è¯•ç¯å¢ƒç®¡ç†...")
#     async with aiohttp.ClientSession() as session:
#         try:
#             # åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒ
#             async with session.get('http://localhost:8001/environments') as response:
#                 if response.status == 200:
#                     env_data = await response.json()
#                     environments = env_data.get('environments', [])
#                     print(f"å‘ç° {len(environments)} ä¸ªç¯å¢ƒ:")
#                     for env in environments:
#                         print(f"  - {env}")
                        
#                         # è·å–ç¯å¢ƒçŠ¶æ€
#                         env_status_url = f'http://localhost:8001/environments/{env}/status'
#                         async with session.get(env_status_url) as env_response:
#                             if env_response.status == 200:
#                                 env_status = await env_response.json()
#                                 print(f"    å·¥ä½œæµæ€»æ•°: {env_status['total_workflows']}")
#                                 print(f"    çŠ¶æ€ç»Ÿè®¡: {env_status['workflow_status_counts']}")
#                 else:
#                     print(f"è·å–ç¯å¢ƒåˆ—è¡¨å¤±è´¥: {response.status}")
#         except Exception as e:
#             print(f"ç¯å¢ƒç®¡ç†æµ‹è¯•é”™è¯¯: {e}")

# async def test_complex_workflow():
#     """æµ‹è¯•å¤æ‚å·¥ä½œæµ"""
#     print("\næµ‹è¯•å¤æ‚å·¥ä½œæµ...")
    
#     environment_id = "123"
    
#     # å¤æ‚å·¥ä½œæµï¼šæ•°æ®åŠ è½½ -> å¡«å……ç¼ºå¤±å€¼ -> ç§»åŠ¨å¹³å‡ -> æ ‡å‡†å·® -> å½’ä¸€åŒ– -> å¼‚å¸¸æ£€æµ‹ -> å‘Šè­¦
#     complex_workflow = {
#         "name": "å¤æ‚æ•°æ®å¤„ç†ç®¡é“",
#         "description": "å®Œæ•´çš„æ•°æ®é¢„å¤„ç†å’Œå¼‚å¸¸æ£€æµ‹æµæ°´çº¿",
#         "steps": [
#             {
#                 "name": "load_data",
#                 "task_type": "DATA",
#                 "data_source_config": {
#                     "source_type": "influxdb",
#                     "query_config": {
#                         "measurement": "test_measurement",
#                         "fields": ["value"],
#                         "start": "-4h",             
#                         "stop": "now()",
#                         "pivot": True   
#                     }
#                 }
#             },
#             {
#                 "name": "fill_missing",
#                 "task_type": "FUNCTION",
#                 "function_name": "FillNA",
#                 "config": {
#                     "field": "value",
#                     "method": "interpolate"
#                 },
#                 "dependencies": ["load_data"]
#             },
#             {
#                 "name": "moving_average",
#                 "task_type": "FUNCTION",
#                 "function_name": "MovingAverage",
#                 "config": {
#                     "field": "value",
#                     "window": 5,
#                     "method": "simple"
#                 },
#                 "dependencies": ["fill_missing"]
#             },
#             {
#                 "name": "calculate_std",
#                 "task_type": "FUNCTION",
#                 "function_name": "StdDeviation",
#                 "config": {
#                     "field": "value",
#                     "window": 10
#                 },
#                 "dependencies": ["moving_average"]
#             },
#             {
#                 "name": "normalize_data",
#                 "task_type": "FUNCTION",
#                 "function_name": "Normalize",
#                 "config": {
#                     "field": "value",
#                     "method": "zscore"
#                 },
#                 "dependencies": ["calculate_std"]
#             },
#             {
#                 "name": "detect_anomalies",
#                 "task_type": "FUNCTION",
#                 "function_name": "ZScore",
#                 "config": {
#                     "field": "value_norm",
#                     "threshold": 2.0
#                 },
#                 "dependencies": ["normalize_data"]
#             },
#             {
#                 "name": "final_alarm",
#                 "task_type": "FUNCTION",
#                 "function_name": "CombinedAlarm",
#                 "config": {
#                     "conditions": [
#                         {"field": "value", "operator": "gt", "value": 60},
#                         {"field": "is_anomaly", "operator": "eq", "value": True}
#                     ],
#                     "logic": "and"
#                 },
#                 "dependencies": ["detect_anomalies"]
#             }
#         ]
#     }
    
#     async with aiohttp.ClientSession() as session:
#         try:
#             # æäº¤å¤æ‚å·¥ä½œæµ
#             submit_url = f'http://localhost:8001/environments/{environment_id}/workflows/submit'
#             payload = {
#                 "workflow": complex_workflow,
#                 "submitted_by": "complex_test"
#             }
            
#             async with session.post(submit_url, json=payload) as response:
#                 if response.status == 200:
#                     result = await response.json()
#                     workflow_id = result.get('workflow_id')
#                     print(f"å¤æ‚å·¥ä½œæµå·²æäº¤ï¼ŒID: {workflow_id}")
                    
#                     # ç›‘æ§è¿›åº¦
#                     status_url = f'http://localhost:8001/environments/{environment_id}/workflows/{workflow_id}/status'
                    
#                     for i in range(60):  # æ›´é•¿çš„ç­‰å¾…æ—¶é—´
#                         await asyncio.sleep(3)
#                         async with session.get(status_url) as status_response:
#                             if status_response.status == 200:
#                                 status_info = await status_response.json()
#                                 workflow_status = status_info['status']
#                                 task_stats = status_info.get('task_statistics', {})
#                                 print(f"å¤æ‚å·¥ä½œæµçŠ¶æ€ {i+1}: {workflow_status} - {task_stats}")
                                
#                                 if workflow_status in ['completed', 'failed']:
#                                     break
                    
#                     # è·å–æœ€ç»ˆç»“æœ
#                     if workflow_status == 'completed':
#                         result_url = f'http://localhost:8001/environments/{environment_id}/workflows/{workflow_id}/tasks/final_alarm/result'
#                         async with session.get(result_url) as result_response:
#                             if result_response.status == 200:
#                                 result_data = await result_response.json()
#                                 if result_data:
#                                     result_df = pd.DataFrame(result_data)
#                                     print(f"\nå¤æ‚å·¥ä½œæµç»“æœ: {result_df.shape}")
                                    
#                                     # ä¿å­˜å¤æ‚å·¥ä½œæµç»“æœ
#                                     result_df.to_csv('complex_workflow_result.csv', index=False)
#                                     print("å¤æ‚å·¥ä½œæµç»“æœå·²ä¿å­˜åˆ° complex_workflow_result.csv")
#                 else:
#                     print(f"å¤æ‚å·¥ä½œæµæäº¤å¤±è´¥: {response.status}")
#                     print(await response.text())
                    
#         except Exception as e:
#             print(f"å¤æ‚å·¥ä½œæµæµ‹è¯•é”™è¯¯: {e}")

# if __name__ == "__main__":
#     async def main():
#         await test_health_check()
#         await test_functions_list()
#         await test_environments()
#         await test_workflow()
#         await test_complex_workflow()
    
#     asyncio.run(main())